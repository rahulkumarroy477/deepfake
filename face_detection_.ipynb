{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved face to extracted_faces\\real_09__podium_speech_happy.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\real_09__podium_speech_happy.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\real_13__hugging_happy.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\real_14__podium_speech_happy.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\real_14__podium_speech_happy.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\real_03__outside_talking_still_laughing.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\real_03__outside_talking_still_laughing.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\real_12__outside_talking_still_laughing.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\real_12__outside_talking_still_laughing.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\real_13__talking_angry_couch.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\real_08__exit_phone_room.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\real_08__exit_phone_room.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\real_12__exit_phone_room.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\real_12__exit_phone_room.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\real_03__talking_against_wall.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\real_03__talking_against_wall.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\real_12__walk_down_hall_angry.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\real_12__walk_down_hall_angry.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\fake_02_09__kitchen_pan__HIH8YA82.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\fake_02_09__kitchen_pan__HIH8YA82.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\fake_06_26__kitchen_still__L5BVR5L9.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\fake_06_26__kitchen_still__L5BVR5L9.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\fake_05_16__walk_down_hall_angry__OSXCUOHX.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\fake_05_16__walk_down_hall_angry__OSXCUOHX.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\fake_07_26__walk_down_hall_angry__FGNGC2GT.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\fake_07_26__walk_down_hall_angry__FGNGC2GT.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\fake_06_26__kitchen_pan__L5BVR5L9.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\fake_06_26__kitchen_pan__L5BVR5L9.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\fake_06_02__walk_down_hall_angry__37DH75GQ.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\fake_06_02__walk_down_hall_angry__37DH75GQ.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\fake_06_25__walking_and_outside_surprised__MI9BDQ7M.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\fake_06_25__walking_and_outside_surprised__MI9BDQ7M.mp4_frame2.jpg\n",
      "Saved face to extracted_faces\\fake_02_21__kitchen_pan__Z0XHPQAR.mp4_frame1.jpg\n",
      "Saved face to extracted_faces\\fake_02_21__kitchen_pan__Z0XHPQAR.mp4_frame2.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "# Set paths\n",
    "DATASET_PATH = \"FF++\"\n",
    "REAL_PATH = os.path.join(DATASET_PATH, \"real\")\n",
    "FAKE_PATH = os.path.join(DATASET_PATH, \"fake\")\n",
    "OUTPUT_PATH = \"extracted_faces\"\n",
    "\n",
    "# Parameters\n",
    "NUM_VIDEOS = 10\n",
    "\n",
    "# Load the pre-trained face detector (Haar Cascade)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "# Helper function to extract two middle frames and crop the face\n",
    "def extract_and_crop_frames(video_path):\n",
    "    \"\"\"Extract the two middle frames of a video and crop the face portions.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        return None, None\n",
    "\n",
    "    # Get total number of frames\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Extract the two middle frames\n",
    "    middle_frame_index1 = total_frames // 3\n",
    "    middle_frame_index2 = (2 * total_frames) // 3\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, middle_frame_index1)\n",
    "    ret, frame1 = cap.read()\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, middle_frame_index2)\n",
    "    ret, frame2 = cap.read()\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Detect faces and crop them from the frames\n",
    "    face1 = crop_face(frame1)\n",
    "    face2 = crop_face(frame2)\n",
    "\n",
    "    return face1, face2\n",
    "\n",
    "# Function to crop the face from a frame using the face detector\n",
    "def crop_face(frame):\n",
    "    \"\"\"Detect and crop the face from the given frame.\"\"\"\n",
    "    if frame is None:\n",
    "        return None\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        return None  # No face detected\n",
    "\n",
    "    # Assume the first detected face is the one we want (for simplicity)\n",
    "    x, y, w, h = faces[0]\n",
    "    face = frame[y:y + h, x:x + w]\n",
    "\n",
    "    return face\n",
    "\n",
    "# Function to save the face image\n",
    "def save_face_image(face, label, video_name, frame_number):\n",
    "    \"\"\"Save the face image to the output directory.\"\"\"\n",
    "    if face is not None:\n",
    "        face_filename = f\"{label}_{video_name}_frame{frame_number}.jpg\"\n",
    "        face_path = os.path.join(OUTPUT_PATH, face_filename)\n",
    "        cv2.imwrite(face_path, face)\n",
    "        print(f\"Saved face to {face_path}\")\n",
    "\n",
    "# Randomly select 5 videos from each folder\n",
    "real_videos = random.sample(os.listdir(REAL_PATH), NUM_VIDEOS)\n",
    "fake_videos = random.sample(os.listdir(FAKE_PATH), NUM_VIDEOS)\n",
    "\n",
    "# Process real videos\n",
    "for video in real_videos:\n",
    "    video_path = os.path.join(REAL_PATH, video)\n",
    "    face1, face2 = extract_and_crop_frames(video_path)\n",
    "    if face1 is not None:\n",
    "        save_face_image(face1, \"real\", video, 1)\n",
    "    if face2 is not None:\n",
    "        save_face_image(face2, \"real\", video, 2)\n",
    "\n",
    "# Process fake videos\n",
    "for video in fake_videos:\n",
    "    video_path = os.path.join(FAKE_PATH, video)\n",
    "    face1, face2 = extract_and_crop_frames(video_path)\n",
    "    if face1 is not None:\n",
    "        save_face_image(face1, \"fake\", video, 1)\n",
    "    if face2 is not None:\n",
    "        save_face_image(face2, \"fake\", video, 2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
